{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from daal.data_management import AOSNumericTable\n",
    "from daal.data_management import SOANumericTable\n",
    "from daal.data_management import BlockDescriptor_Intc\n",
    "from daal.data_management import BlockDescriptor\n",
    "from daal.data_management import BlockDescriptor_Float64\n",
    "from daal.data_management import readOnly\n",
    "from daal.data_management import readWrite\n",
    "from daal.data_management import data_feature_utils\n",
    "from daal.data_management import HomogenNumericTable\n",
    "from daal.data_management import NumericTableIface\n",
    "from daal.data_management import MergedNumericTable\n",
    "from daal.data_management import FileDataSource\n",
    "from daal.data_management import DataSourceIface\n",
    "from daal.data_management import packed_mask\n",
    "\n",
    "from daal.algorithms.linear_regression import training\n",
    "from daal.algorithms.linear_regression import prediction\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Introduction to Data Science and Intel DAAL\n",
    "===========================================\n",
    "\n",
    "\n",
    "Raphael Mendes de Oliveira Cóbe\n",
    "\n",
    "rmcobe@ncc.unesp.br"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# NCC/Unesp\n",
    "\n",
    "* GridUnesp\n",
    "    * 256 WorkerNodes\n",
    "    \n",
    "* Sprace\n",
    "    * Tier-2 Cern\n",
    "    * 1PB Raw Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Science\n",
    "\n",
    "* Recently open field that put together lots of concepts of other fields, such as:\n",
    "  * Data Mining;\n",
    "  * Data Cleaning;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Intel Data Analytics Acceleration Library\n",
    "* Delivers high application performance across spectrum of Intel®-architecture devices\n",
    "* Speeds time-to-value through data source and environment integration \n",
    "* Reduces application development time via wide selection of pre-optimized advanced analytics algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Management\n",
    "\n",
    "* Data Table\n",
    "<center><img src=\"datatable.png\" width=400 style=\"transform:rotate(90deg);\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Data Management and Data Structures\n",
    "\n",
    "* **Heterogeneous Tables** are used when there are multiple data types in a data set (e.g.double, string, etc.) \n",
    "    * Structures supported: **Structures of Arrays (SoA)** and **Arrays of Structures (AoS)**. \n",
    "* **Homogeneous Tables** are used when the data set has only one type of data. \n",
    "    * Two types of homogeneous tables: **dense** and **sparse**. \n",
    "* **Matrices** are used when the application requires matrix algebra type workloads\n",
    "    * Three kinds of matrices supported: **dense matrix**, **packed symmetric matrix**, and **packed triangular matri-ces**. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# AOS vs SOA\n",
    "\n",
    "<center><img src=\"aos.png\"/></center>\n",
    "<center><img src=\"soa.png\" style=\"height:300px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Loading Data from a NumPy Array (AOS)\n",
    "\n",
    "* Loading from a NumPy Array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "points = np.array([(0.5, -1.3, 1, 100.1),\n",
    "                   (2.5, -3.3, 2, 200.2),\n",
    "                   (4.5, -5.3, 2, 350.3),\n",
    "                   (6.5, -7.3, 0, 470.4),\n",
    "                   (8.5, -9.3, 1, 270.5)],\n",
    "                  dtype=[('x','f4'), ('y','f4'), \n",
    "                         ('categ','i4'), ('value','f8')])  \n",
    "\n",
    "\n",
    "dataTable = AOSNumericTable(points)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Retrieving values of a Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* By Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.5]\n",
      " [ 6.5]\n",
      " [ 8.5]]\n"
     ]
    }
   ],
   "source": [
    "nObservations = len(points)\n",
    "nFeatures = len(points[0])\n",
    "firstReadRow = 2\n",
    "readFeatureIdx = 0\n",
    "\n",
    "floatBlock = BlockDescriptor_Float64()\n",
    "dataTable.getBlockOfColumnValues(readFeatureIdx, firstReadRow,\n",
    "                                 nObservations, readOnly, floatBlock)\n",
    "dataTable.releaseBlockOfColumnValues(floatBlock)\n",
    "print(floatBlock.getArray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Retrieving values of a Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* By Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block of Rows:\n",
      "[[  3.           3.29999995   1.4        -30.        ]\n",
      " [  4.           3.4000001    1.6        -40.        ]\n",
      " [  5.           3.5          1.8        -50.        ]]\n"
     ]
    }
   ],
   "source": [
    "firstReadRow = 2\n",
    "nRead = 3\n",
    "doubleBlock = BlockDescriptor_Float64()\n",
    "dataTable.getBlockOfRows(firstReadRow, nRead, readOnly, doubleBlock)\n",
    "\n",
    "print(\"Block of Rows:\")\n",
    "print(doubleBlock.getArray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Loading Data from a NumPy Array (SOA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def toString(v):\n",
    "    if v == data_feature_utils.DAAL_CATEGORICAL:\n",
    "        return \"DAAL_CATEGORICAL\"\n",
    "    elif v == data_feature_utils.DAAL_ORDINAL:\n",
    "        return \"DAAL_ORDINAL\"\n",
    "    elif v == data_feature_utils.DAAL_CONTINUOUS:\n",
    "        return \"DAAL_CONTINUOUS\"\n",
    "    else:\n",
    "        return \"[Unknown FeatureType]\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "nObservations = 10\n",
    "nFeatures = 4\n",
    "\n",
    "dDataSOA = np.array([1.0, 1.2, 1.4, 1.6, 1.8, 2.0, 2.2, 2.4, 2.6, 2.8], dtype=np.float64)\n",
    "fDataSOA = np.array([3.1, 3.2, 3.3, 3.4, 3.5, 3.6, 3.7, 3.8, 3.9, 4.0], dtype=np.float32)\n",
    "iDataSOA = np.array([-10, -20, -30, -40, -50, -60, -70, -80, -90, -100], dtype=np.int32)\n",
    "cDataSOA = np.array([1, 2, 3, 4, 5, 1, 2, 3, 4, 5], dtype=np.uint8)\n",
    "\n",
    "dataTable = SOANumericTable(nFeatures, nObservations)\n",
    "dataTable.setArray(cDataSOA, 0)\n",
    "dataTable.setArray(fDataSOA, 1)\n",
    "dataTable.setArray(dDataSOA, 2)\n",
    "dataTable.setArray(iDataSOA, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Setting and Retrieving data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* Setting datatypes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dict = dataTable.getDictionary()\n",
    "dict[0].featureType = data_feature_utils.DAAL_CONTINUOUS\n",
    "dict[1].featureType = data_feature_utils.DAAL_CONTINUOUS\n",
    "dict[2].featureType = data_feature_utils.DAAL_CONTINUOUS\n",
    "dict[3].featureType = data_feature_utils.DAAL_CATEGORICAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* Retrieving datatypes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataTypes:\n",
      "0: DAAL_CONTINUOUS, 1: DAAL_CONTINUOUS, 2: DAAL_CONTINUOUS, 3: DAAL_CATEGORICAL, "
     ]
    }
   ],
   "source": [
    "pDictionary = dataTable.getDictionary()\n",
    "print(\"\\nDataTypes:\")\n",
    "for i in range(0, nFeatures):\n",
    "    featureType = pDictionary[i].featureType\n",
    "    print(\"{}: {}\".format(i, toString(featureType)), end=', ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Merging data\n",
    "\n",
    "* `MergedNumericTable`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data1 = np.array([(0.0, 0.1, 0.2, 0.3, 0.4),\n",
    "                  (1.0, 1.1, 1.2, 1.3, 1.4),\n",
    "                  (2.0, 2.1, 2.2, 2.3, 2.4),\n",
    "                  (3.0, 3.1, 3.2, 3.3, 3.4),\n",
    "                  (4.0, 4.1, 4.2, 4.3, 4.4),])\n",
    "\n",
    "data2 = np.array([(0.5, 0.6, 0.7, 0.8, 0.9, 1),\n",
    "                  (1.5, 1.6, 1.7, 1.8, 1.9, 2),\n",
    "                  (2.5, 2.6, 2.7, 2.8, 2.9, 3),\n",
    "                  (3.5, 3.6, 3.7, 3.8, 3.9, 4),\n",
    "                  (4.5, 4.6, 4.7, 4.8, 4.9, 5),])\n",
    "\n",
    "\n",
    "dataTable1 = HomogenNumericTable(data1)\n",
    "dataTable2 = HomogenNumericTable(data2)\n",
    "\n",
    "dataTable = MergedNumericTable()\n",
    "dataTable.addNumericTable(dataTable1)\n",
    "dataTable.addNumericTable(dataTable2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Merging data\n",
    "\n",
    "* Modifying data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.   3.1  3.2  3.3  3.4  3.5  3.6  3.7  3.8  3.9  4. ]\n",
      "[[ 10.  10.  10.  10.  10.  10.  10.  10.  10.  10.  10.]]\n"
     ]
    }
   ],
   "source": [
    "nFeatures1 = 5\n",
    "nFeatures2 = 6\n",
    "firstReadRow = 3\n",
    "nRead = 1\n",
    "\n",
    "\n",
    "block = BlockDescriptor_Float64()\n",
    "dataTable.getBlockOfRows(firstReadRow, nRead, readWrite, block)\n",
    "print(block.getArray().flatten())\n",
    "\n",
    "selected_row = block.getArray()\n",
    "for i in range(0,len(selected_row[0])):\n",
    "    selected_row[0][i] = 10\n",
    "    \n",
    "print(block.getArray())\n",
    "dataTable.releaseBlockOfRows(block)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Merging data\n",
    "\n",
    "* Modifying data (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 10.  10.  10.  10.  10.]]\n",
      "[[ 10.  10.  10.  10.  10.  10.]]\n"
     ]
    }
   ],
   "source": [
    "dataTable1.getBlockOfRows(firstReadRow, nRead, readOnly, block)\n",
    "print(block.getArray())\n",
    "dataTable1.releaseBlockOfRows(block)\n",
    "\n",
    "dataTable2.getBlockOfRows(firstReadRow, nRead, readOnly, block)\n",
    "print(block.getArray())\n",
    "dataTable2.releaseBlockOfRows(block)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Reading from CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations read: 435\n"
     ]
    }
   ],
   "source": [
    "nFeatures = 4\n",
    "nOutcomes = 1\n",
    "\n",
    "trainDatasetFileName = './housing-train.csv'\n",
    "\n",
    "trainDataSource = FileDataSource(trainDatasetFileName, \n",
    "                                 DataSourceIface.notAllocateNumericTable,\n",
    "                                 DataSourceIface.doDictionaryFromContext)\n",
    "\n",
    "trainData = HomogenNumericTable(nFeatures, 0, NumericTableIface.notAllocate)\n",
    "trainOutcome = HomogenNumericTable(nOutcomes, 0, NumericTableIface.notAllocate)\n",
    "\n",
    "mergedData = MergedNumericTable(trainOutcome, trainData)\n",
    "\n",
    "nObservations = trainDataSource.loadDataBlock(mergedData)\n",
    "\n",
    "print(\"Observations read: {}\".format(nObservations))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def printNumericTable(data_table, message='', num_printed_rows=0, num_printed_cols=0,\n",
    "                      interval=10):\n",
    "    num_rows = data_table.getNumberOfRows()\n",
    "    num_cols = data_table.getNumberOfColumns()\n",
    "    layout = data_table.getDataLayout()\n",
    "\n",
    "    if num_printed_rows != 0:\n",
    "        num_printed_rows = min(num_rows, num_printed_rows)\n",
    "    else:\n",
    "        num_printed_rows = num_rows\n",
    "\n",
    "    if num_printed_cols != 0:\n",
    "        num_printed_cols = min(num_cols, num_printed_cols)\n",
    "    else:\n",
    "        num_printed_cols = num_cols\n",
    "\n",
    "    block = BlockDescriptor()\n",
    "    if isFull(layout) or layout == NumericTableIface.csrArray:\n",
    "        data_table.getBlockOfRows(0, num_rows, readOnly, block)\n",
    "        printArray(block.getArray(), num_printed_cols, num_printed_rows,\n",
    "                   num_cols, message, interval)\n",
    "        data_table.releaseBlockOfRows(block)\n",
    "    else:\n",
    "        packed_table = data_table.getBlockOfRowsAsDouble(0, num_rows)\n",
    "\n",
    "        if isLower(layout):\n",
    "            printLowerArray(packed_table, num_printed_rows, message, interval)\n",
    "        elif isUpper(layout):\n",
    "            printUpperArray(packed_table, num_printed_cols, num_printed_rows,\n",
    "                            num_cols, message, interval)\n",
    "        \n",
    "def isFull(layout):\n",
    "    layout_int = int(layout)\n",
    "    if packed_mask & layout_int:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def printArray(array, num_printed_cols, num_printed_rows, num_cols, message,\n",
    "               interval=10, flt64=True):\n",
    "    print(message)\n",
    "    flat_array = array.flatten()\n",
    "    decimals = '3' if flt64 else '0'\n",
    "    for i in range(num_printed_rows):\n",
    "        for j in range(num_printed_cols):\n",
    "            print(\"{:<{width}.{dec}f}\".format(\n",
    "                flat_array[i * num_cols + j], width=interval, dec=decimals), end=''\n",
    "            )\n",
    "        print()\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression coefficients:\n",
      "-6356.393 6.127     2760.738  16551.026 7322.687  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "algorithm = training.Batch_Float64NormEqDense()\n",
    "                                                                                                   \n",
    "algorithm.input.set(training.data, trainData)\n",
    "algorithm.input.set(training.dependentVariables, trainOutcome)\n",
    "                                                                                                   \n",
    "trainingResult = algorithm.compute()\n",
    "printNumericTable(trainingResult.get(training.model).getBeta(), \"Linear Regression coefficients:\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Testing your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "testDatasetFileName = './housing-test.csv'\n",
    "\n",
    "testDataSource = FileDataSource(\n",
    "    testDatasetFileName, DataSourceIface.doAllocateNumericTable,\n",
    "    DataSourceIface.doDictionaryFromContext\n",
    ")\n",
    "\n",
    "testData = HomogenNumericTable(nFeatures, 0, NumericTableIface.notAllocate)\n",
    "testGroundTruth = HomogenNumericTable(nOutcomes, 0, NumericTableIface.notAllocate)\n",
    "mergedData = MergedNumericTable(testGroundTruth,testData)\n",
    "\n",
    "testDataSource.loadDataBlock(mergedData)\n",
    "\n",
    "algorithm = prediction.Batch()\n",
    "\n",
    "algorithm.input.setTable(prediction.data, testData)\n",
    "algorithm.input.setModel(prediction.model, trainingResult.get(training.model))\n",
    "\n",
    "predictionResult = algorithm.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Testing your Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression prediction results: (first 10 rows):\n",
      "77584.291 \n",
      "97463.689 \n",
      "54689.190 \n",
      "65962.833 \n",
      "75165.556 \n",
      "47366.503 \n",
      "55175.751 \n",
      "47366.503 \n",
      "62841.671 \n",
      "65407.807 \n",
      "\n",
      "Ground truth (first 10 rows):\n",
      "75000.000 \n",
      "132000.000\n",
      "60000.000 \n",
      "65000.000 \n",
      "69000.000 \n",
      "51900.000 \n",
      "57000.000 \n",
      "65000.000 \n",
      "79500.000 \n",
      "72500.000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "printNumericTable(predictionResult.get(prediction.prediction), \n",
    "                  \"Linear Regression prediction results: (first 10 rows):\", 10)\n",
    "printNumericTable(testGroundTruth, \"Ground truth (first 10 rows):\", 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What is included?\n",
    "\n",
    "* Algorithms for:\n",
    "    * **Pre-processing**, **Transformation**, **Analysis**, **Modeling**.\n",
    "\n",
    "<center><img src=\"intel-daal-all-data-analysis-stages.png\"/></center>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
